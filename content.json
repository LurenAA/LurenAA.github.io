{"meta":{"title":"lurenaaのblog","subtitle":"","description":"","author":"两天宇宙人","url":"http://yoursite.com","root":"/"},"pages":[{"title":"404 Not Found","date":"2019-11-21T19:53:41.634Z","updated":"2019-11-21T19:53:41.634Z","comments":true,"path":"404.html","permalink":"http://yoursite.com/404.html","excerpt":"","text":"404 Not Found **很抱歉，您访问的页面不存在** 可能是输入地址有误或该地址已被删除"},{"title":"关于","date":"2019-11-21T19:51:46.860Z","updated":"2019-11-21T19:51:46.860Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2019-11-21T19:52:14.465Z","updated":"2019-11-21T19:52:14.465Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"friends","date":"2019-11-21T19:32:31.000Z","updated":"2019-11-21T20:04:05.184Z","comments":true,"path":"friends/index.html","permalink":"http://yoursite.com/friends/index.html","excerpt":"","text":""},{"title":"","date":"2019-11-21T19:53:01.465Z","updated":"2019-11-21T19:53:01.465Z","comments":true,"path":"mylist/index.html","permalink":"http://yoursite.com/mylist/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2019-11-21T19:52:40.413Z","updated":"2019-11-21T19:52:40.413Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"projects","date":"2019-11-21T19:32:31.000Z","updated":"2019-11-21T19:32:31.327Z","comments":true,"path":"projects/index.html","permalink":"http://yoursite.com/projects/index.html","excerpt":"","text":""},{"title":"归档","date":"2019-11-21T20:12:46.614Z","updated":"2019-11-21T20:12:46.614Z","comments":true,"path":"blog/archives/index.html","permalink":"http://yoursite.com/blog/archives/index.html","excerpt":"","text":""}],"posts":[{"title":"二分查找","slug":"alg1","date":"2020-01-07T14:24:36.000Z","updated":"2020-01-07T16:24:45.451Z","comments":true,"path":"2020/01/07/alg1/","link":"","permalink":"http://yoursite.com/2020/01/07/alg1/","excerpt":"","text":"时间复杂度logN 二分查找的实现可以分为两种，一种是递归式的、另一种是循环式的😜递归式 123456789101112int BinarySearch(vector&lt;int&gt;&amp; a,int lo,int ho, int key) &#123; // if(lo &gt; ho) return -1; // int mid = (lo + ho) / 2; // if(a[mid] &gt; key) return BinarySearch(a, lo, mid - 1, key); // else if(a[mid] &lt; key) BinarySearch(a, mid + 1, ho, key); // else return mid; if(lo &gt;= ho) return -1; int mid = (lo + ho) / 2; if(a[mid] &gt; key) return BinarySearch(a, lo, mid, key); else if(a[mid] &lt; key) BinarySearch(a, mid + 1, ho, key); else return mid;&#125; &emsp;&emsp;区间的开闭自由选取，主要是要统一，如果要求传入左闭右开区间，那么在函数内部的处理也要保持左闭右开。 🈶非递归式 123456789101112int BinarySearch(vector&lt;int&gt;&amp; a, int key) &#123; int lo = 0, ho = a.size(), mid; while(lo &lt; ho) &#123; mid = (lo + ho) / 2; if(a[mid] &gt; key) ho = mid; else if(a[mid] &lt; key) lo = mid + 1; else return mid; &#125; return -1;&#125; 递归要满足三个原则： 递归总有一个最简单的情况—方法的第一句总是一个包含return的条件语句。 递归调用总要尝试取解决一个规模更小的子问题。 递归调用的父问题和子问题之间不应该有交集。","categories":[],"tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"libuv源码分析（6）uv_queue_work","slug":"libuv6","date":"2019-11-26T12:06:58.000Z","updated":"2019-11-26T12:56:52.025Z","comments":true,"path":"2019/11/26/libuv6/","link":"","permalink":"http://yoursite.com/2019/11/26/libuv6/","excerpt":"","text":"🏤问题来由&emsp;&emsp;在使用libuv的过程中，我们难免遇见的一个问题是，有一些库没有异步、只能同步运行，这种情况该怎么办呢？比如mysql-connector-cpp。 &emsp;&emsp;首先要说的是，直接在回调函数中执行mysql-connector-cpp这种会阻塞的操作是不符合Libuv的reactor模式的。 123456void handle_json_lab(std::shared_ptr&lt;smpHttp::HttpRequest&gt; req,std::shared_ptr&lt;smpHttp::HttpResponse&gt; res) &#123; try&#123; Session mq = cli.getSession(); auto sqlres = mq.sql(\"Select content FROM labimformation where type = 'labIntroduction'\").execute(); ... &emsp;&emsp;上面这样便是错误的案例。我在写这个项目时，之前就采用了这样的错误做法。&emsp;&emsp;我的这个项目是个http后台，我在接受到POST请求，直接在回调函数中执行mysql操作，这时整个主线程就阻塞住了1，而这就意味着我的http后台不再能接受任何请求，只能等待mysql操作完成后，回调函数返回。而这个mysql的操作耗时一般在3s以上，这对我这个Http后台来说是毁灭性的打击。。。。 1：用户的回调函数是在work->done函数的最后执行的，而work->done是在主线程uv_run中的is_poll中唤醒loop->wq_async后执行的,在work->done函数中阻塞意味着在主线程阻塞住了，uv_run中的事件循环卡住，不再能接受request（这部分不清楚可以去看我的libuv源码分析文章） 🌆解决办法&emsp;&emsp;在手册Thread pool work scheduling中为我们这样的需求提供了这样一个函数：uv_queue_work(uv_loop_t* loop, uv_work_t* req, uv_work_cb work_cb, uv_after_work_cb after_work_cb)。 &emsp;&emsp;这个函数就是上面我们问题的解决办法。但是要注意的是uv_async_t不可以替代这个。虽然都是执行用户的函数。async是让用户函数直接被主线程在uv_run中运行，而uv_queue_work是将work_cb提交给子线程执行，完成后通知主线程，主线程在uv_run中执行after_work_cb。 &emsp;&emsp;总结下来就是：uv_async_t用来执行不阻塞的任务，uv_queue_work执行要阻塞的任务（考虑到线程切换的消耗一般不用来执行不阻塞的任务） 🉐看看源码&emsp;&emsp;这一部分可以结合这我的这篇文章-libuv源码分析（5）uv_fs_*来看。可以作为佐证，libuv中对着这类没有自带异步版本的阻塞操作的处理是一样的：让子线程去执行这个任务，避免阻塞主线程的事件循环，完成后子线程通知主线程。uv_queue_work源码： 123456789101112131415161718int uv_queue_work(uv_loop_t* loop, uv_work_t* req, uv_work_cb work_cb, uv_after_work_cb after_work_cb) &#123; if (work_cb == NULL) return UV_EINVAL; uv__req_init(loop, req, UV_WORK); req-&gt;loop = loop; req-&gt;work_cb = work_cb; req-&gt;after_work_cb = after_work_cb; uv__work_submit(loop, &amp;req-&gt;work_req, UV__WORK_CPU, uv__queue_work, uv__queue_done); return 0;&#125; 再结合我的这篇文章-libuv源码分析（5）uv_fs_*中uv_fs_*函数的源码，这些操作可以总结成以下代码： 12345678UV_REQ_INIT(req, typ); //初始化基类uv_req_t uv__req_register(loop, req); //添加loop中request的计数，避免uv_run中uv__loop_alive返回0，使得主线程uv_run退出...//这里是针对不同类型的操作特有的初始化部分uv__work_submit(loop, &amp;req-&gt;work_req, UV__WORK_CPU, //操作类型 uv__queue_work, //要阻塞的操作，在fs中是uv__fs_work uv__queue_done); //完成后的回调，在fs中是uv__fs_done","categories":[],"tags":[{"name":"libuv","slug":"libuv","permalink":"http://yoursite.com/tags/libuv/"}]},{"title":"libuv源码分析（5）uv_fs_*","slug":"libuv5","date":"2019-11-25T18:57:15.000Z","updated":"2019-11-25T19:41:02.563Z","comments":true,"path":"2019/11/26/libuv5/","link":"","permalink":"http://yoursite.com/2019/11/26/libuv5/","excerpt":"","text":"uv_fs_*&emsp;&emsp;uv_fs_*这一系列的函数基本是一致的，它们的逻辑大概是如下： 123456//x代表一种操作open、write等int uv_fs_x(...uv_fs_t* req...) &#123; INIT(x); //uv_fs_t和其基类uv_req_t的基本初始化 ... //这里是每个操作各自不同对于req的初始化 POST; //提交这个任务&#125; INIT&emsp;&emsp;INIT这个宏定义函数没有特别的地方，就是把req初始化，该置0的置0。 POST&emsp;&emsp;其实现如下： 1234567891011121314151617#define POST do &#123; //dowhile包裹作用域 if (cb != NULL) &#123; uv__req_register(loop, req); uv__work_submit(loop, &amp;req-&gt;work_req, UV__WORK_FAST_IO, uv__fs_work, uv__fs_done); return 0; &#125; else &#123; uv__fs_work(&amp;req-&gt;work_req); return req-&gt;result; &#125; &#125; while (0) &emsp;&emsp;这里通过有无回调函数来决定调用同步版本还是异步版本。 http://docs.libuv.org/en/v1.x/fs.htmllibuv provides a wide variety of cross-platform sync and async file system operations. All functions defined in this document take a callback, which is allowed to be NULL. If the callback is NULL the request is completed synchronously, otherwise it will be performed asynchronously. &emsp;&emsp;uv__fs_work这个函数就是文件操作的封装，所有的文件操作都通过这个函数来完成，即使是异步，最终也要在别的线程中同步执行这个函数。 &emsp;&emsp;uv__fs_done这个函数会调用用户给的回调函数，这个函数会在uv_run中的is_poll函数中得到执行。 &emsp;&emsp;uv__work_submit函数的实现是这样的： 12345678910void uv__work_submit(uv_loop_t* loop,struct uv__work* w,enum uv__work_kind kind, void (*work)(struct uv__work* w),void (*done)(struct uv__work* w, int status)) &#123; uv_once(&amp;once, init_once); w-&gt;loop = loop; w-&gt;work = work; w-&gt;done = done; post(&amp;w-&gt;wq, kind);&#125; &emsp;&emsp;uv_once(&amp;once, init_once);是初始化多个线程，我在我的第三篇文章中有介绍。不过当时对于子线程运行的worker函数没有提及，work函数大概是这样的： 123456789101112131415161718192021222324252627282930static void worker(void* arg) &#123; ... uv_mutex_lock(&amp;mutex); for (;;) &#123; while (QUEUE_EMPTY(&amp;wq)...) &#123; idle_threads += 1; uv_cond_wait(&amp;cond, &amp;mutex); idle_threads -= 1; &#125; q = QUEUE_HEAD(&amp;wq); ... QUEUE_REMOVE(q); QUEUE_INIT(q); ... w = QUEUE_DATA(q, struct uv__work, wq); w-&gt;work(w); uv_mutex_lock(&amp;w-&gt;loop-&gt;wq_mutex); w-&gt;work = NULL; QUEUE_INSERT_TAIL(&amp;w-&gt;loop-&gt;wq, &amp;w-&gt;wq); uv_async_send(&amp;w-&gt;loop-&gt;wq_async); uv_mutex_unlock(&amp;w-&gt;loop-&gt;wq_mutex); uv_mutex_lock(&amp;mutex); ... &#125;&#125; &emsp;&emsp;我去掉了对于slow_io的处理，大致是这样一个过程。 &emsp;&emsp;一开始线程会卡在uv_cond_wait这里，直到被uv_cond_signal唤醒，如果唤醒时wq队列中有任务，它就会执行任务，w-&gt;work(w)也就是调用uv__fs_work。然后把w放入loop-&gt;wq（为了uv__fs_done的执行）。 &emsp;&emsp;uv_async_send调用让loop-&gt;wq_async可读，主线程就从uv_run中的uv__io_poll的epoll_pwait中醒来，wq_async的回调函数会遍历loop-&gt;wq执行w-&gt;done。（我的第四篇文章有讲这一部分的详细内容） 谁来触发uv_cond_signal唤醒子线程呢？🥣uv__work_submit中的post函数： 123456uv_mutex_lock(&amp;mutex);...QUEUE_INSERT_TAIL(&amp;wq, q);if (idle_threads &gt; 0) uv_cond_signal(&amp;cond);uv_mutex_unlock(&amp;mutex); &emsp;&emsp;我再次省略了slow_io的部分，因为它们只是特殊处理。 &emsp;&emsp;该函数有空闲的线程就唤醒，不然就阻塞该线程。","categories":[],"tags":[{"name":"libuv","slug":"libuv","permalink":"http://yoursite.com/tags/libuv/"}]},{"title":"libuv源码分析（4）async","slug":"libuv4","date":"2019-11-24T18:19:34.000Z","updated":"2019-11-25T19:24:48.508Z","comments":true,"path":"2019/11/25/libuv4/","link":"","permalink":"http://yoursite.com/2019/11/25/libuv4/","excerpt":"","text":"uv_async_init&emsp;&emsp;libuv中async的开端在uv_loop_init函数中： 12345678//前面省略err = uv_async_init(loop, &amp;loop-&gt;wq_async, uv__work_done);if (err) goto fail_async_init;uv__handle_unref(&amp;loop-&gt;wq_async);loop-&gt;wq_async.flags |= UV_HANDLE_INTERNAL;//后面省略 &emsp;&emsp;loop-&gt;wq_async是个uv_async_t类型，它用于线程work函数调用最后处理loop-&gt;wq中的回调，暂时不用管,我在我的第五篇文章会讲到它的用途。&emsp;&emsp;我们来看uv_async_init内部： 12345678910111213int err;err = uv__async_start(loop);if (err) return err;uv__handle_init(loop, (uv_handle_t*)handle, UV_ASYNC);handle-&gt;async_cb = async_cb;handle-&gt;pending = 0;QUEUE_INSERT_TAIL(&amp;loop-&gt;async_handles, &amp;handle-&gt;queue);uv__handle_start(handle);return 0; &emsp;&emsp;第五行以后的操作就是初始化基类uv_handle_t以及子类uv_async_t，然后将这个handle放入loop-&gt;queue(放uv_handle_t的队列)以及放入loop-&gt;async_handles（放uv_async_t的队列）中，然后uv__handle_start中将loop-&gt;active_handles加一。&emsp;&emsp;总而言之，第五行以后的内容就是初始化uv_async_t，可以理解成uv_async_t的构造函数。&emsp;&emsp;uv__async_start则不一样，它是初始化函数，它只会调用一次（一般情况是在uv_loop_init中调用），我们先看下它的实现： 1234567891011121314151617181920static int uv__async_start(uv_loop_t* loop) &#123; int pipefd[2]; int err; if (loop-&gt;async_io_watcher.fd != -1) return 0; err = uv__async_eventfd(); if (err &gt;= 0) &#123; pipefd[0] = err; pipefd[1] = -1; &#125; //中间省略 uv__io_init(&amp;loop-&gt;async_io_watcher, uv__async_io, pipefd[0]); uv__io_start(loop, &amp;loop-&gt;async_io_watcher, POLLIN); loop-&gt;async_wfd = pipefd[1]; return 0;&#125; &emsp;&emsp;看第三行loop-&gt;async_io_watcher.fd，当你调用过一次这个函数后，loop-&gt;async_io_watcher.fd不会等于-1，以后你初始化uv_async_t类型变量，调用uv_async_init函数时，uv__async_start都是直接返回的。&emsp;&emsp;我省略掉了中间如果eventfd没有在当前系统下实现时的兼容性处理。总的来说，就是初始化loop-&gt;async_io_watcher。uv__io_t是为epoll设计的结构体。这里你肯定感觉很懵逼，请坚持一下，最后我会梳理一下总体的整个过程。&emsp;&emsp;uv__io_t的实现是这样的： 12345678uv__io_t&#123; uv__io_cb cb; //回调函数 void* watcher_queue[2]; //放入loop-&gt;watcher_queue void* pending_queue[2]; //同理 unsigned int pevents; /* Pending event mask i.e. mask at next tick. */ unsigned int events; /* Current event mask. */ int fd; //文件描述符，用于epoll注册&#125; &emsp;&emsp;这里uv__io_init函数是初始化loop-&gt;async_io_watcher这个结构体： 123456QUEUE_INIT(&amp;w-&gt;pending_queue);QUEUE_INIT(&amp;w-&gt;watcher_queue);w-&gt;cb = cb;w-&gt;fd = fd; //前面我们的eventfdw-&gt;events = 0;w-&gt;pevents = 0; &emsp;&emsp;uv__io_start将loop-&gt;async_io_watcher放入loop-&gt;watcher_queue。还有对于loop-&gt;nfds大小的处理。 1234567if (QUEUE_EMPTY(&amp;w-&gt;watcher_queue)) QUEUE_INSERT_TAIL(&amp;loop-&gt;watcher_queue, &amp;w-&gt;watcher_queue);if (loop-&gt;watchers[w-&gt;fd] == NULL) &#123; loop-&gt;watchers[w-&gt;fd] = w; loop-&gt;nfds++;&#125; &emsp;&emsp;第四行以后的操作是为了在epoll后，我们得到struct event结构体，我们从event-&gt;data.fd可以得到fd，那我们如何获取到对应的uv__io_t呢？ 就是通过loop-&gt;watchers这个数组。 uv_async_send123456789101112131415161718int uv_async_send(uv_async_t* handle) &#123; /* Do a cheap read first. */ if (ACCESS_ONCE(int, handle-&gt;pending) != 0) return 0; /* Tell the other thread we're busy with the handle. */ if (cmpxchgi(&amp;handle-&gt;pending, 0, 1) != 0) return 0; /* Wake up the other thread's event loop. */ uv__async_send(handle-&gt;loop); /* Tell the other thread we're done. */ if (cmpxchgi(&amp;handle-&gt;pending, 1, 2) != 1) abort(); return 0;&#125; &emsp;&emsp;ACCESS_ONCE： 12#define ACCESS_ONCE(type, var) \\ (*(volatile type*) &amp;(var)) &emsp;&emsp;这里调用一次ACCESS_ONCE，是为了告诉编译器，handle-&gt;pending可能被其他线程修改，所以别给我乱优化。&emsp;&emsp;cmpxchgi是原子操作compare_and_change。pending的有三个取值0，1，2。0代表闲置、1代表忙（比如uv_async_send调用途中）、2代表完成。loop-&gt;async_io_watcher调用uv__async_io时，会遍历loop-&gt;async_handles，通过pending来判断哪些回调该被执行。&emsp;&emsp;uv__async_send就是向loop-&gt;async_io_watcher.fd（eventfd）写（这里关系到eventfd的机制，不懂可以man eventfd）。 整体调用过程&emsp;&emsp;这里总体归纳一下async的过程。&emsp;&emsp;1.在loop_uv_init中初始化async_io_watcher，它的fd为eventfd，值为0，不可读。&emsp;&emsp;2.用户uv_async_init注册uv_async_t变量，被添加到loop-&gt;async_handles，设置回调函数。&emsp;&emsp;3.如果对uv_async_t变量调用uv_async_send，那么uv_async_t变量的pending变为2（done），并且向eventfd写，loop-&gt;async_io_watcher可读了。&emsp;&emsp;4.在uv_run的uv__io_poll中，每次都会把loop-&gt;watchers注册到epoll中，第四步这个过程在每次事件循环中都在执行。如果async_io_watcher的fd不可读，就没它事儿。如果可读，async_io_watcher的回调函数uv__async_io执行，它遍历loop-&gt;async_handles，将其中pending为2的uv_async_t变量移除队列，并执行其回调函数。 看源码后写的小DEMO： https://github.com/LurenAA/simple_imitation_of_libuv","categories":[],"tags":[{"name":"libuv","slug":"libuv","permalink":"http://yoursite.com/tags/libuv/"}]},{"title":"ssh: connect to host github.com port 22: Connection refused","slug":"problems1","date":"2019-11-24T09:25:01.000Z","updated":"2019-11-24T15:54:24.892Z","comments":true,"path":"2019/11/24/problems1/","link":"","permalink":"http://yoursite.com/2019/11/24/problems1/","excerpt":"","text":"12cd vim .ssh/config 你会发现这是一个新文件，在其中添加以下文字： 123456Host github.comUser 你的用户名（例如97860xx@qq.com）Hostname ssh.github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsaPort 443 然后保存退出（代码如下）。 1:wq 接下来测试一下： 1ssh -T git@github.com 出现下面的画面：在图片倒数第五行的地方会询问是否建立连接，输入yes即可。","categories":[],"tags":[{"name":"遇见的问题","slug":"遇见的问题","permalink":"http://yoursite.com/tags/%E9%81%87%E8%A7%81%E7%9A%84%E9%97%AE%E9%A2%98/"}]},{"title":"libuv源码分析（3）init_threads","slug":"libuv3","date":"2019-11-17T18:14:58.000Z","updated":"2019-11-24T15:54:16.931Z","comments":true,"path":"2019/11/18/libuv3/","link":"","permalink":"http://yoursite.com/2019/11/18/libuv3/","excerpt":"","text":"由来&emsp;&emsp;在我们第一次提交io操作时，会有uv_once被调用，来检测是否初始化过线程池，如果没有则立刻初始化线程池。所以说线程池并非一开始在uv_run的时候或者在loop中初始化的，而是在io操作开始前。我以uv_open为例子画一下UML图如下：在uv_open中先初始化req，然后准备提交work，提交前会调用uv_once检测是否初始化线程池，没有则初始化。 init_onceuv_once实现如下： 1234567891011121314#define UV_ONCE_INIT PTHREAD_ONCE_INITstatic uv_once_t once = UV_ONCE_INIT;static void init_once(void) &#123;#ifndef _WIN32 /* Re-initialize the threadpool after fork. * Note that this discards the global mutex and condition as well * as the work queue. */ if (pthread_atfork(NULL, NULL, &amp;reset_once)) abort();#endif init_threads();&#125; 在uv__work_submit中uv_once是这样被调用的： 1234void uv__work_submit(...) &#123; uv_once(&amp;once, init_once); ...&#125; &emsp;&emsp;这一部分可以参看TLPI 31.2部分，libuv多做了pthread_atfork的处理。&emsp;&emsp;pthread_atfork注册reset_once函数，在fork之后重置once，保证在libuv循环中如果你fork了一个进程，如果在那个新的进程中你也启动一个libuv，init_threads()能被调用。 init_threads🐤条件变量&emsp;&emsp;libuv初始化条件变量时，调用自己的uv_cond_init，这个函数只做了一件事情，就是将条件变量的时钟设置为相对时间，这一点是值得我们自己写代码时参考的，相对时间不受系统时间的影响。 12345int uv_cond_init(uv_cond_t* cond) &#123; ... err = pthread_condattr_setclock(&amp;attr, CLOCK_MONOTONIC); ...&#125; 🥛互斥锁&emsp;&emsp;初始化互斥锁时，调用uv_mutex_init，在DEBUG时，libuv会将互斥锁设置为PTHREAD_MUTEX_ERRORCHECK，这样能自我检测是否为死锁，不过这会消耗性能，所以在运行时设置为默认值。 123456789int uv_mutex_init(uv_mutex_t* mutex) &#123;#if defined(NDEBUG) || !defined(PTHREAD_MUTEX_ERRORCHECK) return UV__ERR(pthread_mutex_init(mutex, NULL));#else ... if (pthread_mutexattr_settype(&amp;attr, PTHREAD_MUTEX_ERRORCHECK)) abort(); ...&#125; PTHREAD_MUTEX_ERRORCHECKThis type of mutex provides error checking. A thread attempting to relock this mutex without first unlocking it shall return with an error. A thread attempting to unlock a mutex which another thread has locked shall return with an error. A thread attempting to unlock an unlocked mutex shall return with an error. 🥡信号量&emsp;&emsp;初始化每个线程时，libuv用信号量来保证init_threads函数在初始化完所有线程后退出。 1234567891011if (uv_sem_init(&amp;sem, 0)) abort(); for (i = 0; i &lt; nthreads; i++) if (uv_thread_create(threads + i, worker, &amp;sem)) abort(); for (i = 0; i &lt; nthreads; i++) uv_sem_wait(&amp;sem); uv_sem_destroy(&amp;sem); 在linux下并且glibc版本大于2.21时，uv_sem_init(&amp;sem, 0)和sem_init(&amp;sem, 0)是一样的，没有额外的处理。线程创建好后，在worker函数中会调用uv_sem_post释放信号量。 12345static void worker(void* arg) &#123; ... uv_sem_post((uv_sem_t*) arg); ... &#125; 🥚uv_thread_create&emsp;&emsp;uv_thread_create做的事情就是设置线程的stack大小，然后创建它。thread_stack_size函数获取栈大小，有一些是跨平台兼容性的处理。 123lim.rlim_cur -= lim.rlim_cur % (rlim_t) getpagesize(); 和if (lim.rlim_cur &gt;= PTHREAD_STACK_MIN) return lim.rlim_cur; 上面两行的限制是来源于pthread_attr_setstacksize函数，一下是pthread_attr_setstacksize函数man手册的一部分。 ERRORS pthread_attr_setstacksize() can fail with the following error:EINVAL The stack size is less than PTHREAD_STACK_MIN (16384) bytes. On some systems, pthread_attr_setstacksize() can fail with the error EINVAL if stacksize is not a multiple of the system page size. 1234567891011121314151617181920212223242526272829static size_t thread_stack_size(void) &#123;#if defined(__APPLE__) || defined(__linux__) struct rlimit lim; if (getrlimit(RLIMIT_STACK, &amp;lim)) abort(); if (lim.rlim_cur != RLIM_INFINITY) &#123; /* pthread_attr_setstacksize() expects page-aligned values. */ lim.rlim_cur -= lim.rlim_cur % (rlim_t) getpagesize(); /* Musl's PTHREAD_STACK_MIN is 2 KB on all architectures, which is * too small to safely receive signals on. * * Musl's PTHREAD_STACK_MIN + MINSIGSTKSZ == 8192 on arm64 (which has * the largest MINSIGSTKSZ of the architectures that musl supports) so * let's use that as a lower bound. * * We use a hardcoded value because PTHREAD_STACK_MIN + MINSIGSTKSZ * is between 28 and 133 KB when compiling against glibc, depending * on the architecture. */ if (lim.rlim_cur &gt;= 8192) if (lim.rlim_cur &gt;= PTHREAD_STACK_MIN) return lim.rlim_cur; &#125; ... return 2 &lt;&lt; 20; /* glibc default. */#endif 😂无趣的是在linux Ubuntus我的环境下测试时，attr的默认stacksize和thread_stack_size函数设置到的是一样的值。下面是我的测试代码： 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;assert.h&gt;#include &lt;stdio.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;uv.h&gt;#include &lt;string&gt;#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;malloc.h&gt;#include &lt;time.h&gt;#include &lt;iostream&gt;#include &lt;sys/time.h&gt;#include &lt;sys/resource.h&gt;using namespace std;void a(void *) &#123; cout &lt;&lt; 123 &lt;&lt; endl;&#125;size_t stack_page() &#123; rlimit x; assert(getrlimit(RLIMIT_STACK, &amp;x) == 0); size_t stack_size = x.rlim_cur - x.rlim_cur % getpagesize(); cout &lt;&lt; stack_size &lt;&lt; endl; if(stack_size &gt; PTHREAD_STACK_MIN) return stack_size;&#125;int main() &#123; pthread_attr_t attr; assert(pthread_attr_init(&amp;attr) == 0); size_t stack_size; pthread_attr_getstacksize(&amp;attr, &amp;stack_size); cout &lt;&lt; stack_size &lt;&lt; endl; stack_size = stack_page(); pthread_attr_setstacksize(&amp;attr, stack_size); pthread_t p1; pthread_create(&amp;p1, &amp;attr, (void* (*)(void*))a, nullptr); pthread_attr_destroy(&amp;attr); return 0;&#125;","categories":[],"tags":[{"name":"libuv","slug":"libuv","permalink":"http://yoursite.com/tags/libuv/"}]},{"title":"libuv源码分析（2）uv__loop_alive","slug":"libuv2","date":"2019-11-16T09:58:11.000Z","updated":"2019-11-24T15:54:12.877Z","comments":true,"path":"2019/11/16/libuv2/","link":"","permalink":"http://yoursite.com/2019/11/16/libuv2/","excerpt":"","text":"前言&emsp;&emsp;上一篇说了一下整体的事件循环，对于UV_RUN_DEFAULT模式来调用uv_run来说，uv__loop_alive就决定了是否退出，这一篇看一下uv__loop_alive的源码。 详情12345static int uv__loop_alive(const uv_loop_t* loop) &#123; return uv__has_active_handles(loop) || uv__has_active_reqs(loop) || loop-&gt;closing_handles != NULL;&#125; &emsp;&emsp;可见loop的状态取决于三个方面：handles、reqs、closing_handles handles&emsp;&emsp;uv__has_active_handles就是检查loop-&gt;active_handles值是否大于0. 12#define uv__has_active_handles(loop) \\ ((loop)-&gt;active_handles &gt; 0) 12345678910111213141516171819/* Handle types. */typedef struct uv_loop_s uv_loop_t;typedef struct uv_handle_s uv_handle_t;typedef struct uv_dir_s uv_dir_t;typedef struct uv_stream_s uv_stream_t;typedef struct uv_tcp_s uv_tcp_t;typedef struct uv_udp_s uv_udp_t;typedef struct uv_pipe_s uv_pipe_t;typedef struct uv_tty_s uv_tty_t;typedef struct uv_poll_s uv_poll_t;typedef struct uv_timer_s uv_timer_t;typedef struct uv_prepare_s uv_prepare_t;typedef struct uv_check_s uv_check_t;typedef struct uv_idle_s uv_idle_t;typedef struct uv_async_s uv_async_t;typedef struct uv_process_s uv_process_t;typedef struct uv_fs_event_s uv_fs_event_t;typedef struct uv_fs_poll_s uv_fs_poll_t;typedef struct uv_signal_s uv_signal_t; &emsp;&emsp;handles列表如上。handle在调用时，会包含一个函数的调用，就是uv__handle_start。下图所示，是哪些函数调用了uv__handle_start。有一些handle不在其中，可能与其调用方式有关，我暂时无法解释 1234567#define uv__handle_start(h) \\ do &#123; \\ if (((h)-&gt;flags &amp; UV_HANDLE_ACTIVE) != 0) break; \\ (h)-&gt;flags |= UV_HANDLE_ACTIVE; \\ if (((h)-&gt;flags &amp; UV_HANDLE_REF) != 0) uv__active_handle_add(h); \\ &#125; \\ while (0) &emsp;&emsp;uv__handle_start函数在调用时，会调用uv__active_handle_add，uv__active_handle_add就是将loop-&gt;active_handles++ 12345#define uv__active_handle_add(h) \\ do &#123; \\ (h)-&gt;loop-&gt;active_handles++; \\ &#125; \\ while (0) &emsp;&emsp;相应的在handle结束时有uv__active_handle_rm的调用，(h)-&gt;loop-&gt;active_handles减一。 12345#define uv__active_handle_rm(h) \\ do &#123; \\ (h)-&gt;loop-&gt;active_handles--; \\ &#125; \\ while (0) req&emsp;&emsp;uv__has_active_reqs和handle的道理一样，是检测(loop)-&gt;active_reqs.count &gt; 0。active_reqs是个共用体，它的另一个用途暂时我还不知道。 12#define uv__has_active_reqs(loop) \\ ((loop)-&gt;active_reqs.count &gt; 0) 12345678910/* Request types. */typedef struct uv_req_s uv_req_t;typedef struct uv_getaddrinfo_s uv_getaddrinfo_t;typedef struct uv_getnameinfo_s uv_getnameinfo_t;typedef struct uv_shutdown_s uv_shutdown_t;typedef struct uv_write_s uv_write_t;typedef struct uv_connect_s uv_connect_t;typedef struct uv_udp_send_s uv_udp_send_t;typedef struct uv_fs_s uv_fs_t;typedef struct uv_work_s uv_work_t; &emsp;&emsp;uv__req_register(loop, req)等同于handle的uv__active_handle_add。uv__req_register在uv__req_init中调用，几乎（漏网的暂时没法解释 ）每个req在初始化时都调用了uv__req_init。 123456789101112#define uv__req_init(loop, req, typ) \\ do &#123; \\ UV_REQ_INIT(req, typ); \\ uv__req_register(loop, req); \\ &#125; \\ while (0) #define uv__req_register(loop, req) \\ do &#123; \\ (loop)-&gt;active_reqs.count++; \\ &#125; \\ while (0) &emsp;&emsp;下图所示是那些函数调用了uv__req_init，由名称我们可以看出来它们是属于哪些req的。&emsp;&emsp;同理，还有uv__req_unregister。 123456#define uv__req_unregister(loop, req) \\ do &#123; \\ assert(uv__has_active_reqs(loop)); \\ (loop)-&gt;active_reqs.count--; \\ &#125; \\ while (0) closing_handles&emsp;&emsp;要关闭的handle会以链表的形式挂在loop-&gt;closing_handles上。这个操作通过调用uv__make_close_pending来实现。 123456void uv__make_close_pending(uv_handle_t* handle) &#123; assert(handle-&gt;flags &amp; UV_HANDLE_CLOSING); assert(!(handle-&gt;flags &amp; UV_HANDLE_CLOSED)); handle-&gt;next_closing = handle-&gt;loop-&gt;closing_handles; handle-&gt;loop-&gt;closing_handles = handle;&#125; 如果closing_handles不为空，那么还需要进入事件循环，去调用关闭的handle的回调函数。","categories":[],"tags":[{"name":"libuv","slug":"libuv","permalink":"http://yoursite.com/tags/libuv/"}]},{"title":"libuv源码分析（1）事件循环分析","slug":"libuv1","date":"2019-11-16T08:45:44.000Z","updated":"2019-11-24T15:54:06.502Z","comments":true,"path":"2019/11/16/libuv1/","link":"","permalink":"http://yoursite.com/2019/11/16/libuv1/","excerpt":"","text":"前言 &emsp;&emsp;libuv总是报出一些让人难以理解的错误😂，作为一个C的项目，不具有Java、JavaScript、php那样的人气，很难百度到一些问题的答案，甚至google也不行。为了用好libuv，也为了学习吧。我开始看libuv的源码，不知道自己能走多远。。。 事件循环 这是官方事件循环的示意图。链接-&gt;官方图片位置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950int uv_run(uv_loop_t* loop, uv_run_mode mode) &#123; int timeout; int r; int ran_pending; r = uv__loop_alive(loop); if (!r) uv__update_time(loop); while (r != 0 &amp;&amp; loop-&gt;stop_flag == 0) &#123; uv__update_time(loop); uv__run_timers(loop); ran_pending = uv__run_pending(loop); uv__run_idle(loop); uv__run_prepare(loop); timeout = 0; if ((mode == UV_RUN_ONCE &amp;&amp; !ran_pending) || mode == UV_RUN_DEFAULT) timeout = uv_backend_timeout(loop); uv__io_poll(loop, timeout); uv__run_check(loop); uv__run_closing_handles(loop); if (mode == UV_RUN_ONCE) &#123; /* UV_RUN_ONCE implies forward progress: at least one callback must have * been invoked when it returns. uv__io_poll() can return without doing * I/O (meaning: no callbacks) when its timeout expires - which means we * have pending timers that satisfy the forward progress constraint. * * UV_RUN_NOWAIT makes no guarantees about progress so it's omitted from * the check. */ uv__update_time(loop); uv__run_timers(loop); &#125; r = uv__loop_alive(loop); if (mode == UV_RUN_ONCE || mode == UV_RUN_NOWAIT) break; &#125; /* The if statement lets gcc compile it to a conditional store. Avoids * dirtying a cache line. */ if (loop-&gt;stop_flag != 0) loop-&gt;stop_flag = 0; return r;&#125; &emsp;&emsp;整个事件循环就是在主线程的uv_run（）调用中执行的。我就跟着官方的介绍一步一步来看（官方介绍）。 第一步 The loop concept of ‘now’ is updated. The event loop caches the current time at the start of the event loop tick in order to reduce the number of time-related system calls. &emsp;&emsp;第一步是更新时间。对应代码如下： 1uv__update_time(loop); &emsp;&emsp;总结来说就是调用这个函数，更新时间。uv__update_time实现我下一篇来介绍 第二步 If the loop is alive an iteration is started, otherwise the loop will exit immediately. So, when is a loop considered to be alive? If a loop has active and ref’d handles, active requests or closing handles it’s considered to be alive. 1r = uv__loop_alive(loop); &emsp;&emsp;用uv__loop_alive函数获取loop状态。&emsp;&emsp;如果uv__loop_alive返回零或者loop-&gt;stop_flag == 1说明loop终止，直接跳过循环，到代码最下面（这里有一些性能的处理暂时不管 ），退出： 1234567/* The if statement lets gcc compile it to a conditional store. Avoids * dirtying a cache line. */ if (loop-&gt;stop_flag != 0) loop-&gt;stop_flag = 0; return r; &emsp;&emsp;loop-&gt;stop_flag == 0的一个来源是调用了uv_stop，这个函数在手册中看见。它的源代码也很清晰。 123void uv_stop(uv_loop_t* loop) &#123; loop-&gt;stop_flag = 1;&#125; &emsp;&emsp;如果loop状态OK，那么就进入循环中。 第三步 Due timers are run. All active timers scheduled for a time before the loop’s concept of now get their callbacks called. &emsp;&emsp;对应代码这一部分： 1234567891011121314151617181920uv__run_timers(loop);其实现：void uv__run_timers(uv_loop_t* loop) &#123; struct heap_node* heap_node; uv_timer_t* handle; for (;;) &#123; heap_node = heap_min(timer_heap(loop)); if (heap_node == NULL) break; handle = container_of(heap_node, uv_timer_t, heap_node); if (handle-&gt;timeout &gt; loop-&gt;time) break; uv_timer_stop(handle); uv_timer_again(handle); handle-&gt;timer_cb(handle); &#125;&#125; &emsp;&emsp;将堆里面已经超时的拿出来运行。 第四步 Pending callbacks are called. All I/O callbacks are called right after polling for I/O, for the most part. There are cases, however, in which calling such a callback is deferred for the next loop iteration. If the previous iteration deferred any I/O callback it will be run at this point. 对应： 12345678910111213141516171819202122ran_pending = uv__run_pending(loop);其实现：static int uv__run_pending(uv_loop_t* loop) &#123; QUEUE* q; QUEUE pq; uv__io_t* w; if (QUEUE_EMPTY(&amp;loop-&gt;pending_queue)) return 0; QUEUE_MOVE(&amp;loop-&gt;pending_queue, &amp;pq); while (!QUEUE_EMPTY(&amp;pq)) &#123; q = QUEUE_HEAD(&amp;pq); QUEUE_REMOVE(q); QUEUE_INIT(q); w = QUEUE_DATA(q, uv__io_t, pending_queue); w-&gt;cb(loop, w, POLLOUT); &#125; return 1;&#125; &emsp;&emsp;将loop-&gt;pending_queue中的任务拿出来运行。 第五、六、九步 5.Idle handle callbacks are called. Despite the unfortunate name, idle handles are run on every loop iteration, if they are active 6.Prepare handle callbacks are called. Prepare handles get their callbacks called right before the loop will block for I/O. 9.Check handle callbacks are called. Check handles get their callbacks called right after the loop has blocked for I/O. Check handles are essentially the counterpart of prepare handles. 123uv__run_idle(loop);uv__run_prepare(loop);uv__run_check(loop); &emsp;&emsp;这三部为什么要一起说呢？因为它们的实质是一样的。在每次循环固定的位置调用。&emsp;&emsp;这三个函数定义在loop-watcher.c这个文件里面，它们是用宏定义定义的。只改了idle、prepare、check这三个名字的部分，其余部分函数都是一样的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/* Copyright Joyent, Inc. and other Node contributors. All rights reserved. * * Permission is hereby granted, free of charge, to any person obtaining a copy * of this software and associated documentation files (the \"Software\"), to * deal in the Software without restriction, including without limitation the * rights to use, copy, modify, merge, publish, distribute, sublicense, and/or * sell copies of the Software, and to permit persons to whom the Software is * furnished to do so, subject to the following conditions: * * The above copyright notice and this permission notice shall be included in * all copies or substantial portions of the Software. * * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS * IN THE SOFTWARE. */#include \"uv.h\"#include \"internal.h\"#define UV_LOOP_WATCHER_DEFINE(name, type) \\ int uv_##name##_init(uv_loop_t* loop, uv_##name##_t* handle) &#123; \\ uv__handle_init(loop, (uv_handle_t*)handle, UV_##type); \\ handle-&gt;name##_cb = NULL; \\ return 0; \\ &#125; \\ \\ int uv_##name##_start(uv_##name##_t* handle, uv_##name##_cb cb) &#123; \\ if (uv__is_active(handle)) return 0; \\ if (cb == NULL) return UV_EINVAL; \\ QUEUE_INSERT_HEAD(&amp;handle-&gt;loop-&gt;name##_handles, &amp;handle-&gt;queue); \\ handle-&gt;name##_cb = cb; \\ uv__handle_start(handle); \\ return 0; \\ &#125; \\ \\ int uv_##name##_stop(uv_##name##_t* handle) &#123; \\ if (!uv__is_active(handle)) return 0; \\ QUEUE_REMOVE(&amp;handle-&gt;queue); \\ uv__handle_stop(handle); \\ return 0; \\ &#125; \\ \\ void uv__run_##name(uv_loop_t* loop) &#123; \\ uv_##name##_t* h; \\ QUEUE queue; \\ QUEUE* q; \\ QUEUE_MOVE(&amp;loop-&gt;name##_handles, &amp;queue); \\ while (!QUEUE_EMPTY(&amp;queue)) &#123; \\ q = QUEUE_HEAD(&amp;queue); \\ h = QUEUE_DATA(q, uv_##name##_t, queue); \\ QUEUE_REMOVE(q); \\ QUEUE_INSERT_TAIL(&amp;loop-&gt;name##_handles, q); \\ h-&gt;name##_cb(h); \\ &#125; \\ &#125; \\ \\ void uv__##name##_close(uv_##name##_t* handle) &#123; \\ uv_##name##_stop(handle); \\ &#125;UV_LOOP_WATCHER_DEFINE(prepare, PREPARE)UV_LOOP_WATCHER_DEFINE(check, CHECK)UV_LOOP_WATCHER_DEFINE(idle, IDLE) 第七步 Poll timeout is calculated. Before blocking for I/O the loop calculates for how long it should block. These are the rules when calculating the timeout:If the loop was run with the UV_RUN_NOWAIT flag, the timeout is 0.If the loop is going to be stopped (uv_stop() was called), the timeout is 0.If there are no active handles or requests, the timeout is 0.If there are any idle handles active, the timeout is 0.If there are any handles pending to be closed, the timeout is 0.If none of the above cases matches, the timeout of the closest timer is taken, or if there are no active timers, infinity. 12if ((mode == UV_RUN_ONCE &amp;&amp; !ran_pending) || mode == UV_RUN_DEFAULT) timeout = uv_backend_timeout(loop); &emsp;&emsp;这部分是取决于uv_run的模式的特殊处理，暂时不细看。 第八步 The loop blocks for I/O. At this point the loop will block for I/O for the duration calculated in the previous step. All I/O related handles that were monitoring a given file descriptor for a read or write operation get their callbacks called at this point. 1uv__io_poll(loop, timeout); &emsp;&emsp;这一部分对于不同操作系统有所不同，linux是poll，mac是kqueue。 第十步 Close callbacks are called. If a handle was closed by calling uv_close() it will get the close callback called. 1uv__run_closing_handles(loop); &emsp;&emsp;调用各类的close回调函数。 第十一、十二步 11.Special case in case the loop was run with UV_RUN_ONCE, as it implies forward progress. It’s possible that no I/O callbacks were fired after blocking for I/O, but some time has passed so there might be timers which are due, those timers get their callbacks called.12.Iteration ends. If the loop was run with UV_RUN_NOWAIT or UV_RUN_ONCE modes the iteration ends and uv_run() will return. If the loop was run with UV_RUN_DEFAULT it will continue from the start if it’s still alive, otherwise it will also end. &emsp;&emsp;对于uv_run不同模式的一点特殊处理。 12345678910111213141516if (mode == UV_RUN_ONCE) &#123; /* UV_RUN_ONCE implies forward progress: at least one callback must have * been invoked when it returns. uv__io_poll() can return without doing * I/O (meaning: no callbacks) when its timeout expires - which means we * have pending timers that satisfy the forward progress constraint. * * UV_RUN_NOWAIT makes no guarantees about progress so it's omitted from * the check. */ uv__update_time(loop); uv__run_timers(loop); &#125; r = uv__loop_alive(loop); if (mode == UV_RUN_ONCE || mode == UV_RUN_NOWAIT) break; 小结&emsp;&emsp;宏观上梳理一下整个事件循环的过程。","categories":[],"tags":[{"name":"libuv","slug":"libuv","permalink":"http://yoursite.com/tags/libuv/"}]},{"title":"redis基数树rax源码分析(2.5)","slug":"rax3","date":"2019-08-14T10:40:51.000Z","updated":"2019-11-25T19:51:03.317Z","comments":true,"path":"2019/08/14/rax3/","link":"","permalink":"http://yoursite.com/2019/08/14/rax3/","excerpt":"","text":"点点废话&emsp;&emsp;最近没有再将rax的源码往下看，rax对于一个新手来说还是体量过大，在尝试自己写写，在写的时候遇到了一些坑，也体会到了rax的一些写法的精妙之处，记录一下。 宏定义函数的注意点：&emsp;&emsp;我定义了这样一个宏定义函数： 12#define radixNthChild(h, n) \\ (radix_node**)((char*)&amp;h-&gt;data + h-&gt;size + padding(h-&gt;size) + n * sizeof(void*)) 我这样调用这个函数： 1radixNthChild(new_cur, new_cur-&gt;size - 1) 这样一个调用大家觉得有问题吗？嗯，肯定是有问题的，不然我说啥?。 这里，按照我们一般的调用函数的思路，这样一个调用的运行过程是这样的： 计算出new_cur-&gt;size - 1 带入radixNthChild函数 实际上恰恰相反，宏定义的处理在预编译时（g++ -E），宏定义是将对于的定义替换掉，所以在预编译后的结果如下： 12# 363 &quot;radix_tree.c&quot; memcpy((radix_node**)((char*)&amp;new_cur-&gt;data + new_cur-&gt;size + ((sizeof(void*) - (sizeof(radix_node) + new_cur-&gt;size) % sizeof(void*)) &amp; (sizeof(void*) - 1)) + new_cur-&gt;size - 1 * sizeof(void*)), &amp;keyOne, sizeof(void*)); 可以看到是 ： + new_cur-&gt;size - 1 * sizeof(void)而不是我所想的： + （new_cur-&gt;size - 1） * sizeof(void) 可以得出其过程其实是： 函数宏定义替换 运行时计算 结论： 在宏定义函数调用时注意括号的问题，不加括号可能会由于运算符优先级而 导致表达式意义与我们想的有出入? 地址运算注意点先给出这样一个结构体： 123struct test &#123; void* a, *b, *c;&#125;; int main(void) { cout &lt;&lt; sizeof(test) &lt;&lt; endl; test* p = new test; fprintf(stdout, &quot;%p:%p:%p:%p\\n&quot;, p, p + 1, (char*)p + 1, (int*)p+1); return 0; }&emsp;&emsp;在这样一个测试代码中，大家觉得p + 1, (char)p + 1, (int)p+1这三个结果，相对于p的数值相差多少呢？&emsp;&emsp;运行结果是这样的。类型与地址的运算是有着密切关系的。 p + 1是一个默认情况， 这时1的意义是一个p的地址宽度 (char*)p + 1，p被解释为char类型指针，指向的地址被解释为char，于是1就是一个char的地址宽度。 总结： 在计算地址时，要注意运算符左边值的类型。你加上的1可能并不是一个字节的大小。 这是我边看rax边实现的一个小练习，欢迎大家指教：https://github.com/LurenAA/radix_tree ，好想要个star，求求了，兄弟萌:kissing_heart:","categories":[],"tags":[{"name":"rax源码阅读","slug":"rax源码阅读","permalink":"http://yoursite.com/tags/rax%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"}]},{"title":"redis基数树rax源码分析(2)","slug":"rax2","date":"2019-08-12T10:51:18.000Z","updated":"2019-11-25T19:49:43.833Z","comments":true,"path":"2019/08/12/rax2/","link":"","permalink":"http://yoursite.com/2019/08/12/rax2/","excerpt":"","text":"今天我想要说的是rax中的padding这个函数，我查了很多的资料，大家的博客都告诉我们内存对齐提高性能，却没有去分析为什么，是有根据让作者选择这样做？如果只是这样简单的放过，总感觉让人有一丝的遗憾。 &emsp;&emsp;先把主角拉出来： 12#define raxPadding(nodesize) ((sizeof(void*)-((nodesize+4) % sizeof(void*))) &amp; (sizeof(void*)-1)) &emsp;&emsp;首先要说的是raxPadding的作用是：让raxNewNode申请的内存nodesize是8的倍数。 123456789101112raxNode *raxNewNode(size_t children, int datafield) &#123; size_t nodesize = sizeof(raxNode)+children+raxPadding(children)+ sizeof(raxNode*)*children; if (datafield) nodesize += sizeof(void*); raxNode *node = rax_malloc(nodesize); if (node == NULL) return NULL; node-&gt;iskey = 0; node-&gt;isnull = 0; node-&gt;iscompr = 0; node-&gt;size = children; return node;&#125; 第一个问题：对齐的优势&emsp;&emsp;这个并不是我想说的重点，这里是大家都谈到的，也就是经过内存对齐之后，CPU的内存访问速度大大提升。对于我来说，这个结论感觉还是太模糊，这是一个定性的结论，具体的底层细节对于我们初学者来说倒是没必要去深究。 第二个问题：为什么要这么去做？&emsp;&emsp;rax的作者这样的做法其实是参考结构体的做法。举个例子： 123456struct X&#123; char a; int c; double b;&#125;S2; 这样一个结构体，它的大小是多少？答案是16。在c语言的内部，做了这样的内存对齐处理： 这里转载了这篇文章中的很多资源，大家也可以去看看这篇文章，写的很不错。也有更多例子。 回到rax上来&emsp;&emsp; 在rax的raxNode这个结构体中，因为使用了柔性数组，所以在c语言本身是无法帮助我们实现像上面一样的内存对齐的（sizeof(raxNode) == 4,我们申请的内存大小决定了柔性数组的长度，详情请百度柔性数组） ，c语言对于结构体的优化没有包含柔性数组这个部分，所以我们必须自己来接管这一部分的内存对齐，保证程序的运行效率。 typedef struct raxNode { uint32_t iskey:1; /* Does this node contain a key? */ uint32_t isnull:1; /* Associated value is NULL (don&apos;t store it). */ uint32_t iscompr:1; /* Node is compressed. */ uint32_t size:29; /* Number of children, or compressed string len. */ unsigned char data[]; } raxNode; 这是我边看rax边实现的一个小练习，欢迎大家指教：https://github.com/LurenAA/radix_tree ，好想要个star，求求了，兄弟萌:kissing_heart:","categories":[],"tags":[{"name":"rax源码阅读","slug":"rax源码阅读","permalink":"http://yoursite.com/tags/rax%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"}]},{"title":"redis基数树rax源码分析(1)","slug":"rax1","date":"2019-08-11T16:11:44.000Z","updated":"2019-11-25T19:48:25.184Z","comments":true,"path":"2019/08/12/rax1/","link":"","permalink":"http://yoursite.com/2019/08/12/rax1/","excerpt":"","text":"&emsp;&emsp;最近想用libuv写个http服务器，看到了这个开源项目haywire，在看到第39次提交的时候，作者用基数树来存储不同路由的controller，不过在后续版本中改为了使用hash，不过想来不如正好学学基数树，作者使用的基数树是这个版本radix_tree，这个版本缺少注释，且和一般思路不一样的使用的是二叉树而非N叉树，为了理解方便，我选择了注释较多的rax 数据结构&emsp;&emsp;首先要提到的是rax的数据结构设计： 1234567typedef struct raxNode &#123; uint32_t iskey:1; /* Does this node contain a key? */ uint32_t isnull:1; /* Associated value is NULL (don&apos;t store it). */ uint32_t iscompr:1; /* Node is compressed. */ uint32_t size:29; / unsigned char data[];&#125; raxNode; 这里第一个要说到的点是：你觉得这样一个数据结构的大小是多少？24？ 16？ 还是8？&emsp;&emsp;第一个原因是位域，也就是结构体中的冒号： ，冒号在这里声明实际需要使用的位数，iskey，isnull，iscompr，size四个一共加起来32位，占4个字节。&emsp;&emsp;第二个原因是data[]占0个字节。unsigned char data[];这样一个结构在这里并不是理解成一个指针8个字节。而是一个柔性数组的概念，实现一个可变长度。data[1]占结构体1个字节，data[2]占结构体2个字节…….data[13]占13个字节。数组类型的内存是结构体中直接分配的，而不是像指针一样需要我们后来分配。如下图可见： 12345678910typedef struct raxNode &#123; unsigned char data[13];&#125; raxNode;int main(int argc, char *argv[])&#123; printf(&quot;%d\\n&quot;, sizeof(raxNode)); return 0;&#125; data[]&emsp;&emsp;接下来我们还是要谈data，在这里data的意义并不是一个简单的unsigned char数组，它存储的是键值key和radixNode指针两种变量。图来自：https://my.oschina.net/yunqi/blog/3039132data的实际使用方式在大多数时候是以内存地址的方式进行的。 123456#define raxNodeLastChildPtr(n) ((raxNode**) ( \\ ((char*)(n)) + \\ raxNodeCurrentLength(n) - \\ sizeof(raxNode*) - \\ (((n)-&gt;iskey &amp;&amp; !(n)-&gt;isnull) ? sizeof(void*) : 0) \\)) &emsp;&emsp;这是访问最后一个节点的函数（也就是访问图中的A-ptr）。n是一个raxNode*指针，对这个指针指向的地址进行＋操作来得到最后一个节点的地址。 节点的表示图来自：https://my.oschina.net/yunqi/blog/3039132&emsp;&emsp;假设基数树中有“abcd”这个键值的节点。那么它的表示形式是像上图这样的。“abcd”这个节点的value-data存储在图片下半部分的节点处，并且下面一个节点iskey设为1.&emsp;&emsp;为什么不是直接只有图片的上半部分，由图片上半部分那个节点将iskey设置为1并且将值存储在其value·data中呢？像这样： [iskey:1][isnull: 0][iscompr:1][size:4][abcd] [z-ptr ][value-ptr] 先给出结论： 在rax中一个节点的存在（iskey == 1）是由data中对应的子节点来表示的。原因很简单：在这个例子里面，这是一个没有压缩的节点，这一层由a和A两个子节点，如果在当前层次表示，如何分辨你指定的是a还是A？所以用引出子节点来表示。 这是我边看rax边实现的一个小练习，欢迎大家指教：https://github.com/LurenAA/radix_tree ，好想要个star，求求了，兄弟萌:kissing_heart:","categories":[],"tags":[{"name":"rax源码阅读","slug":"rax源码阅读","permalink":"http://yoursite.com/tags/rax%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"}]}]}